{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":87370,"sourceType":"datasetVersion","datasetId":48024}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Personal Bank Loan Classification","metadata":{}},{"cell_type":"markdown","source":"**Aim:** To use different classification models to predict the likelihood that a customer will buy a personal loan.","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"#For reading data visualisation\nimport numpy as np\nimport pandas as pd\nfrom ydata_profiling import ProfileReport\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap, LinearSegmentedColormap\nimport seaborn as sns\n\n#Preprocessing of Data\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, StandardScaler\n\n#Models for Predictions \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n#Model Evaluation\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\nfrom sklearn.metrics import classification_report, RocCurveDisplay, ConfusionMatrixDisplay\nfrom scipy import stats\nfrom sklearn.base import clone \n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-26T18:57:38.255508Z","iopub.execute_input":"2024-06-26T18:57:38.256539Z","iopub.status.idle":"2024-06-26T18:57:45.778968Z","shell.execute_reply.started":"2024-06-26T18:57:38.256482Z","shell.execute_reply":"2024-06-26T18:57:45.777941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading The Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/bank-loan-modelling/Bank_Personal_Loan_Modelling.xlsx', sheet_name='Data')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:57:50.370639Z","iopub.execute_input":"2024-06-26T18:57:50.371971Z","iopub.status.idle":"2024-06-26T18:57:51.700263Z","shell.execute_reply.started":"2024-06-26T18:57:50.371929Z","shell.execute_reply":"2024-06-26T18:57:51.699159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:56.930574Z","iopub.execute_input":"2024-06-26T14:16:56.930915Z","iopub.status.idle":"2024-06-26T14:16:56.947192Z","shell.execute_reply.started":"2024-06-26T14:16:56.930885Z","shell.execute_reply":"2024-06-26T14:16:56.945790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:56.948679Z","iopub.execute_input":"2024-06-26T14:16:56.949020Z","iopub.status.idle":"2024-06-26T14:16:57.002241Z","shell.execute_reply.started":"2024-06-26T14:16:56.948986Z","shell.execute_reply":"2024-06-26T14:16:57.000938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dataset basic information:**\n* The dataset has data on 5000 customers.\n* We have 14 variables including 13 independent variables and 1 dependent variable which is Personal Loan. \n* We have 6 numeric variables: ID , Age , Experience , Income , CC_Avg , Mortgage\n* We have 3 categorical variables: Family , Education , Zip_Code\n* We have 5 Boolean variables: Personal_Loan , Securities Account , CD_Account , Online , Credit_Card","metadata":{}},{"cell_type":"markdown","source":"# Correlation Analysis","metadata":{}},{"cell_type":"code","source":"corr_matrix = df.corr()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:57:56.622683Z","iopub.execute_input":"2024-06-26T17:57:56.623089Z","iopub.status.idle":"2024-06-26T17:57:56.632140Z","shell.execute_reply.started":"2024-06-26T17:57:56.623055Z","shell.execute_reply":"2024-06-26T17:57:56.631065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 9))  # Set the figure size\nsns.heatmap(corr_matrix, annot=True, cmap='Greens', cbar=True)\nplt.title('Heatmap of Feature Correlations')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:57.018657Z","iopub.execute_input":"2024-06-26T14:16:57.019086Z","iopub.status.idle":"2024-06-26T14:16:58.075043Z","shell.execute_reply.started":"2024-06-26T14:16:57.019043Z","shell.execute_reply":"2024-06-26T14:16:58.073952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conclusion \nPersonal Loan is highly correlated with Income, CD_Account, CCAvg.\nExperience is highly correlated with Age. (ρ = 0.99)\nCCAvg is correlated with Income to a good extent. (ρ = 0.58)","metadata":{}},{"cell_type":"markdown","source":"# Data Cleansing","metadata":{}},{"cell_type":"markdown","source":"**1.Noise Treatment**","metadata":{}},{"cell_type":"code","source":"sns.countplot(x=df['Personal Loan'])\nplt.title('No of People who took the loan')\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:58.076292Z","iopub.execute_input":"2024-06-26T14:16:58.076645Z","iopub.status.idle":"2024-06-26T14:16:58.335056Z","shell.execute_reply.started":"2024-06-26T14:16:58.076615Z","shell.execute_reply":"2024-06-26T14:16:58.333781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that more than 4000 people who had their account in the bank didn't take the loan and only around 500 people took the loan.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6),dpi=90)\nplt.scatter(df['Personal Loan'],df['Age'],color='red')\nplt.title(\"Loan WRT Age\")\nplt.xlabel('Personal Loan')\nplt.ylabel('Age')\nplt.xticks(np.arange(0,2,1))\nplt.yticks(np.arange(15,80,5))\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:58.336966Z","iopub.execute_input":"2024-06-26T14:16:58.337411Z","iopub.status.idle":"2024-06-26T14:16:58.608927Z","shell.execute_reply.started":"2024-06-26T14:16:58.337369Z","shell.execute_reply":"2024-06-26T14:16:58.607744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age of those who didn't accepted loan is between 23 and around 67, while people who took the loan is between 25 and 65","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6),dpi=90)\nplt.scatter(df['Personal Loan'],df['Experience'],color='red')\nplt.title(\"Chart\")\nplt.xlabel('Personal Loan')\nplt.ylabel('Experience')\nplt.xticks(np.arange(0,2,1))\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:58.611137Z","iopub.execute_input":"2024-06-26T14:16:58.612154Z","iopub.status.idle":"2024-06-26T14:16:58.854055Z","shell.execute_reply.started":"2024-06-26T14:16:58.612109Z","shell.execute_reply":"2024-06-26T14:16:58.852813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some negative values which is needed to fixed.","metadata":{}},{"cell_type":"code","source":"df[df['Experience']<0]['Experience'].count()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:58.855492Z","iopub.execute_input":"2024-06-26T14:16:58.856823Z","iopub.status.idle":"2024-06-26T14:16:58.865917Z","shell.execute_reply.started":"2024-06-26T14:16:58.856772Z","shell.execute_reply":"2024-06-26T14:16:58.864746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['Experience']<0]['Experience'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:58.867757Z","iopub.execute_input":"2024-06-26T14:16:58.868191Z","iopub.status.idle":"2024-06-26T14:16:58.880898Z","shell.execute_reply.started":"2024-06-26T14:16:58.868150Z","shell.execute_reply":"2024-06-26T14:16:58.879677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These values may be the result of incorrect input or readings, which can simply be corrected by taking absoulte of the values\n","metadata":{}},{"cell_type":"code","source":"df['Experience'] = df['Experience'].apply(abs)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:58.882524Z","iopub.execute_input":"2024-06-26T14:16:58.882868Z","iopub.status.idle":"2024-06-26T14:16:58.894268Z","shell.execute_reply.started":"2024-06-26T14:16:58.882835Z","shell.execute_reply":"2024-06-26T14:16:58.893175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['Experience']<0]['Experience'].count()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:58.895733Z","iopub.execute_input":"2024-06-26T14:16:58.896074Z","iopub.status.idle":"2024-06-26T14:16:58.910791Z","shell.execute_reply.started":"2024-06-26T14:16:58.896045Z","shell.execute_reply":"2024-06-26T14:16:58.909747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6),dpi=90)\nplt.scatter(df['Personal Loan'],df['Income'],color='red')\nplt.title(\"Chart\")\nplt.xlabel('Personal Loan')\nplt.ylabel('Income')\nplt.xticks(np.arange(0,2,1))\nplt.yticks(np.arange(5,300,50))\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:58.915945Z","iopub.execute_input":"2024-06-26T14:16:58.916392Z","iopub.status.idle":"2024-06-26T14:16:59.182833Z","shell.execute_reply.started":"2024-06-26T14:16:58.916324Z","shell.execute_reply":"2024-06-26T14:16:59.181775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can conclude from the graph that people who took loan made around 55 to 205, while people who didn't take the loan have income between 5 to 255.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6),dpi=90)\nplt.scatter(df['Personal Loan'],df['ZIP Code'],color='red')\nplt.title(\"Chart\")\nplt.xlabel('Personal Loan')\nplt.ylabel('ZIP Code')\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:59.184097Z","iopub.execute_input":"2024-06-26T14:16:59.184437Z","iopub.status.idle":"2024-06-26T14:16:59.523223Z","shell.execute_reply.started":"2024-06-26T14:16:59.184406Z","shell.execute_reply":"2024-06-26T14:16:59.522018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a noise in this sample as all other samples are over 90,000 but this is one sample is around 9000.","metadata":{}},{"cell_type":"code","source":"df[df['ZIP Code']<90000]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:59.524677Z","iopub.execute_input":"2024-06-26T14:16:59.524991Z","iopub.status.idle":"2024-06-26T14:16:59.539615Z","shell.execute_reply.started":"2024-06-26T14:16:59.524962Z","shell.execute_reply":"2024-06-26T14:16:59.538399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We found 1 noisy data in ZIP Code. We drop the corresponding sample because it contains 4 digits, while the other values of this feature all have 5 digits:","metadata":{}},{"cell_type":"code","source":"df.drop(df[df['ZIP Code']<20000].index, inplace=True)\ndf.reset_index(drop=True, inplace =True)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:59.541601Z","iopub.execute_input":"2024-06-26T14:16:59.542301Z","iopub.status.idle":"2024-06-26T14:16:59.553012Z","shell.execute_reply.started":"2024-06-26T14:16:59.542257Z","shell.execute_reply":"2024-06-26T14:16:59.551682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=df['Family'])\nplt.title('No of family members')\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:59.554325Z","iopub.execute_input":"2024-06-26T14:16:59.554692Z","iopub.status.idle":"2024-06-26T14:16:59.825738Z","shell.execute_reply.started":"2024-06-26T14:16:59.554662Z","shell.execute_reply":"2024-06-26T14:16:59.824552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped_df = df.groupby('Personal Loan')['Family'].sum().reset_index()\nplt.figure(figsize=(10, 6))\nsns.countplot(x='Family', hue='Personal Loan', data=df, palette='viridis')\nplt.xlabel('No of Family Members')\nplt.ylabel('Count')\nplt.title('No of Family Members and Loan Status')\nplt.legend(title='Loan')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:16:59.827580Z","iopub.execute_input":"2024-06-26T14:16:59.828027Z","iopub.status.idle":"2024-06-26T14:17:00.127590Z","shell.execute_reply.started":"2024-06-26T14:16:59.827966Z","shell.execute_reply":"2024-06-26T14:17:00.126462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No of family members and people who took loan doesn't help us much.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6),dpi=90)\nplt.scatter(df['Personal Loan'],df['CCAvg'],color='red')\nplt.title(\"Chart\")\nplt.xlabel('Personal Loan')\nplt.ylabel('CCAvg')\nplt.xticks(np.arange(0,2,1))\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:00.128929Z","iopub.execute_input":"2024-06-26T14:17:00.129246Z","iopub.status.idle":"2024-06-26T14:17:00.364156Z","shell.execute_reply.started":"2024-06-26T14:17:00.129216Z","shell.execute_reply":"2024-06-26T14:17:00.363013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=df['Education'])\nplt.title('No of educated people')\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:00.365603Z","iopub.execute_input":"2024-06-26T14:17:00.365925Z","iopub.status.idle":"2024-06-26T14:17:00.627454Z","shell.execute_reply.started":"2024-06-26T14:17:00.365895Z","shell.execute_reply":"2024-06-26T14:17:00.626384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"More than 2000 individuals hold undergraduate degrees, while approximately 1500 people are in PhD positions. Additionally, around 1300 individuals have obtained master's degrees.","metadata":{}},{"cell_type":"code","source":"data = df['Mortgage']\nbins = 10\nplt.figure(figsize=(10,6),dpi=90)\nhist, edges, _ = plt.hist(data, bins=bins, edgecolor='black')\n\nfor i in range(bins):\n    plt.text(edges[i] + (edges[i+1] - edges[i])/2, hist[i], str(hist[i]), ha='center', va='bottom')\n\nplt.xticks(np.arange(0,700,50))\nplt.title(\"Chart\")\nplt.xlabel('amount of mortgage')\nplt.ylabel('No of people')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:00.628943Z","iopub.execute_input":"2024-06-26T14:17:00.629343Z","iopub.status.idle":"2024-06-26T14:17:01.059628Z","shell.execute_reply.started":"2024-06-26T14:17:00.629306Z","shell.execute_reply":"2024-06-26T14:17:01.058436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(rc = {'axes.labelsize' : 15})               \nfig, ax = plt.subplots(1, 2, figsize=(15,5), dpi=120)\nsns.histplot(x='Mortgage', data=df, color='royalblue', ax=ax[0])\nsns.boxplot(x='Mortgage', data=df, color='royalblue', ax=ax[1])\nplt.suptitle('Mortgage Distribution', fontsize=20)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:01.061076Z","iopub.execute_input":"2024-06-26T14:17:01.061408Z","iopub.status.idle":"2024-06-26T14:17:01.747709Z","shell.execute_reply.started":"2024-06-26T14:17:01.061374Z","shell.execute_reply":"2024-06-26T14:17:01.746526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[stats.zscore(df['Mortgage'])>3]['Mortgage'].count()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:01.749467Z","iopub.execute_input":"2024-06-26T14:17:01.750171Z","iopub.status.idle":"2024-06-26T14:17:01.762552Z","shell.execute_reply.started":"2024-06-26T14:17:01.750126Z","shell.execute_reply":"2024-06-26T14:17:01.761431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We found 105 records with a Z-score mortgage value greater than 3. Therefore, we consider these 105 records as outliers and filter out these records from our dataset:","metadata":{}},{"cell_type":"code","source":"outlier_indexes = df[stats.zscore(df['Mortgage'])>3].index\ndf.drop(outlier_indexes, inplace=True)\ndf.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:01.763852Z","iopub.execute_input":"2024-06-26T14:17:01.764195Z","iopub.status.idle":"2024-06-26T14:17:01.779214Z","shell.execute_reply.started":"2024-06-26T14:17:01.764164Z","shell.execute_reply":"2024-06-26T14:17:01.777794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing Value Treatment","metadata":{}},{"cell_type":"code","source":"df.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:01.780966Z","iopub.execute_input":"2024-06-26T14:17:01.781540Z","iopub.status.idle":"2024-06-26T14:17:01.795939Z","shell.execute_reply.started":"2024-06-26T14:17:01.781497Z","shell.execute_reply":"2024-06-26T14:17:01.794322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Duplicate Values Treatment","metadata":{}},{"cell_type":"code","source":"df[df.duplicated(keep=False)].sum().sum()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:01.797739Z","iopub.execute_input":"2024-06-26T14:17:01.798171Z","iopub.status.idle":"2024-06-26T14:17:01.815488Z","shell.execute_reply.started":"2024-06-26T14:17:01.798128Z","shell.execute_reply":"2024-06-26T14:17:01.814232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Transformation","metadata":{}},{"cell_type":"markdown","source":"In our data set the CCAVG represents average monthly credit card spending, but Income represents the amount of annual income. To make the units of the features equal, we convert average monthly credit card spending to annual.","metadata":{}},{"cell_type":"code","source":"df['CCAvg'] = df['CCAvg']*12","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:01.817093Z","iopub.execute_input":"2024-06-26T14:17:01.818411Z","iopub.status.idle":"2024-06-26T14:17:01.826257Z","shell.execute_reply.started":"2024-06-26T14:17:01.818325Z","shell.execute_reply":"2024-06-26T14:17:01.824981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model section","metadata":{}},{"cell_type":"code","source":"df.reset_index(inplace=True)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:01.827986Z","iopub.execute_input":"2024-06-26T14:17:01.829116Z","iopub.status.idle":"2024-06-26T14:17:01.859309Z","shell.execute_reply.started":"2024-06-26T14:17:01.829071Z","shell.execute_reply":"2024-06-26T14:17:01.856724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(['index'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:01.861723Z","iopub.execute_input":"2024-06-26T14:17:01.863306Z","iopub.status.idle":"2024-06-26T14:17:01.870634Z","shell.execute_reply.started":"2024-06-26T14:17:01.863256Z","shell.execute_reply":"2024-06-26T14:17:01.869311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAIN TEST SPLIT","metadata":{}},{"cell_type":"code","source":"X = df.drop('Personal Loan', axis=1)\ny = df['Personal Loan'] ","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:01.872533Z","iopub.execute_input":"2024-06-26T14:17:01.872895Z","iopub.status.idle":"2024-06-26T14:17:01.883190Z","shell.execute_reply.started":"2024-06-26T14:17:01.872864Z","shell.execute_reply":"2024-06-26T14:17:01.882012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(dpi=80)\n\ndf['Personal Loan'].value_counts(normalize=True).mul(100).plot(kind='barh', width=0.8, figsize=(10,6))\n\nlabels = df['Personal Loan'].value_counts(normalize=True).mul(100).round(1)\nfor i in labels.index:\n    plt.text(labels[i], i, str(labels[i])+ '%', fontsize=15, weight='bold')\n\nplt.xlim([0, 110])\nplt.xlabel('Frequency Percentage', fontsize=15)\nplt.ylabel('Personal Loan', fontsize=15)\nplt.title('Frequency Percentage of Target Classes', fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:01.884745Z","iopub.execute_input":"2024-06-26T14:17:01.885100Z","iopub.status.idle":"2024-06-26T14:17:02.196261Z","shell.execute_reply.started":"2024-06-26T14:17:01.885070Z","shell.execute_reply":"2024-06-26T14:17:02.195123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that our dataset is very imbalanced.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.197848Z","iopub.execute_input":"2024-06-26T14:17:02.198212Z","iopub.status.idle":"2024-06-26T14:17:02.208986Z","shell.execute_reply.started":"2024-06-26T14:17:02.198181Z","shell.execute_reply":"2024-06-26T14:17:02.207664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_perc = pd.concat([y.value_counts(normalize=True).mul(100).round(1),\n                     y_train.value_counts(normalize=True).mul(100).round(1),\n                     y_test.value_counts(normalize=True).mul(100).round(1)], axis=1)\ndf_perc.columns=['Dataset','Training','Test']\ndf_perc = df_perc.T\n\n# Plot frequency percentages barplot\ndf_perc.plot(kind='barh', stacked=True, figsize=(10,5), width=0.6)\n\n# Add the percentages to our plot\nfor idx, val in enumerate([*df_perc.index.values]):\n    for (percentage, y_location) in zip(df_perc.loc[val], df_perc.loc[val].cumsum()):\n        plt.text(x=(y_location - percentage) + (percentage / 2)-3,\n                 y=idx - 0.05,\n                 s=f'{percentage}%', \n                 color=\"black\",\n                 fontsize=12,\n                 fontweight=\"bold\")\nplt.legend(title='Personal Loan', loc=(1.01,0.8))\nplt.xlabel('Frequency Percentage', fontsize=15)\nplt.title('Frequency Percentage of Target Classes among Training and Test Sets', fontsize=15)\nplt.show()            ","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.210479Z","iopub.execute_input":"2024-06-26T14:17:02.210829Z","iopub.status.idle":"2024-06-26T14:17:02.524323Z","shell.execute_reply.started":"2024-06-26T14:17:02.210798Z","shell.execute_reply":"2024-06-26T14:17:02.523116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# F1 Score function\nTo prevent rewriting the same function over and over.\n","metadata":{}},{"cell_type":"code","source":"def f1_metric(model, X_train, y_train):\n    return f1_score(y_train, model.predict(X_train), average='binary')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.525987Z","iopub.execute_input":"2024-06-26T14:17:02.526451Z","iopub.status.idle":"2024-06-26T14:17:02.532583Z","shell.execute_reply.started":"2024-06-26T14:17:02.526409Z","shell.execute_reply":"2024-06-26T14:17:02.531404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop-column Feature","metadata":{}},{"cell_type":"code","source":"def drop_column_importance(model, X_train, y_train, random_state=0):\n    # List to store feature importances\n    importances = []\n    # Clone the model to ensure it's a fresh instance\n    model_clone = clone(model)\n    # Set random_state for consistency\n    if hasattr(model_clone, 'random_state'):\n        model_clone.random_state = random_state\n    # Train the benchmark model\n    model_clone.fit(X_train, y_train)\n    # Create the cross-validation object using StratifiedKFold\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n    # Score the benchmark model using cross-validation\n    benchmark_score = cross_val_score(model_clone, X_train, y_train, cv=cv, scoring='f1').mean()\n    \n    # Iterate over all features and store feature importance\n    for col in X_train.columns:\n        # Clone the model for each iteration\n        model_clone = clone(model)\n        if hasattr(model_clone, 'random_state'):\n            model_clone.random_state = random_state\n        # Train the model on the dataset with a single feature removed\n        model_clone.fit(X_train.drop(col, axis=1), y_train)\n        # Score the model with the dropped column\n        drop_column_score = cross_val_score(model_clone, X_train.drop(col, axis=1), y_train, cv=cv, scoring='f1').mean()\n        # Calculate and store the importance of the dropped feature\n        importances.append(benchmark_score - drop_column_score)\n    \n    # Return the features along with their importances in a DataFrame\n    importances_df = pd.DataFrame({'feature': X_train.columns, 'feature importance': importances}) \\\n                     .sort_values('feature importance', ascending=False).reset_index(drop=True)\n    \n    return importances_df\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.534568Z","iopub.execute_input":"2024-06-26T14:17:02.534939Z","iopub.status.idle":"2024-06-26T14:17:02.546090Z","shell.execute_reply.started":"2024-06-26T14:17:02.534906Z","shell.execute_reply":"2024-06-26T14:17:02.544408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def drop_column_importance_plot(model, X_train, y_train):\n    # Call drop-column feature importance function\n    df_drop_column = drop_column_importance(model, X_train, y_train, random_state=0)\n    # Rename columns\n    df_drop_column.columns = ['Feature', 'Feature Importance']\n    \n    # Plot barchart\n    plt.figure(figsize=(12,10))\n    sns.barplot(data=df_drop_column, x='Feature Importance', y='Feature', orient='h', color='royalblue')\n    plt.title('Drop Column Feature Importance', fontsize=20)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.548113Z","iopub.execute_input":"2024-06-26T14:17:02.548582Z","iopub.status.idle":"2024-06-26T14:17:02.562615Z","shell.execute_reply.started":"2024-06-26T14:17:02.548543Z","shell.execute_reply":"2024-06-26T14:17:02.561065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"def metrics_calculator(clf, X_test, y_test, model_name):\n    '''\n    This function calculates all desired performance metrics for a given model on test data.\n    '''\n    y_pred = clf.predict(X_test)\n    result = pd.DataFrame(data=[accuracy_score(y_test, y_pred),\n                                precision_score(y_test, y_pred, average='binary'),\n                                recall_score(y_test, y_pred, average='binary'),\n                                f1_score(y_test, y_pred, average='binary'),\n                                roc_auc_score(y_test, clf.predict_proba(X_test)[::,1])],\n                          index=['Accuracy','Precision','Recall','F1-score','AUC'],\n                          columns = [model_name])\n    \n    result = (result * 100).round(2).astype(str) + '%'                            \n    return result","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.564323Z","iopub.execute_input":"2024-06-26T14:17:02.564753Z","iopub.status.idle":"2024-06-26T14:17:02.579944Z","shell.execute_reply.started":"2024-06-26T14:17:02.564720Z","shell.execute_reply":"2024-06-26T14:17:02.578742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_evaluation(clf, X_train, X_test, y_train, y_test, model_name):\n    '''\n    This function provides a complete report of the model's performance including classification reports, \n    confusion matrix and ROC curve.\n    '''\n    sns.set(font_scale=1.2)\n    \n    # Generate classification report for training set\n    y_pred_train = clf.predict(X_train)\n    print(\"\\n\\t  Classification report for training set\")\n    print(\"-\"*55)\n    print(classification_report(y_train, y_pred_train))\n\n    # Generate classification report for test set\n    y_pred_test = clf.predict(X_test)\n    print(\"\\n\\t   Classification report for test set\")\n    print(\"-\"*55)\n    print(classification_report(y_test, y_pred_test))\n    \n    # Create figure and subplots \n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5), dpi=100, gridspec_kw={'width_ratios': [2, 2, 1]})\n    \n    # Plot confusion matrix for test set\n    ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, colorbar=False, ax=ax1)\n    ax1.set_title('Confusion Matrix for Test Data')                                     \n    ax1.grid(False)\n    \n    # Plot ROC curve for test data and display AUC score \n    RocCurveDisplay.from_estimator(clf, X_test, y_test, ax=ax2)\n    ax2.set_xlabel('False Positive Rate')\n    ax2.set_ylabel('True Positive Rate')\n    ax2.set_title('ROC Curve for Test Data (Positive label: 1)')\n    \n    # Report results for the class specified by positive label\n    result = metrics_calculator(clf, X_test, y_test, model_name)\n    table = ax3.table(cellText=result.values, colLabels=result.columns, rowLabels=result.index, loc='center')\n    table.scale(0.6, 2)\n    table.set_fontsize(12)\n    ax3.axis('tight')\n    ax3.axis('off')\n    # Modify color \n    for key, cell in table.get_celld().items():\n        if key[0] == 0:\n            cell.set_color('royalblue')\n    plt.tight_layout()\n    plt.show() ","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.581445Z","iopub.execute_input":"2024-06-26T14:17:02.581836Z","iopub.status.idle":"2024-06-26T14:17:02.594524Z","shell.execute_reply.started":"2024-06-26T14:17:02.581801Z","shell.execute_reply":"2024-06-26T14:17:02.593335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discretization_report(df, clf):\n    '''\n    This function finds the optimal combination of n_bins and strategy for continuous features discretization\n    '''\n    # Define continuous features to perform discretization on\n    cols_to_discretize = ['Age', 'Income', 'CCAvg', 'Mortgage']\n\n    # Define the features (X) and the output labels (y) \n    X = df[cols_to_discretize]\n    y = df['Personal Loan']\n\n    # Split dataset into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n\n    # Define the grid search parameters\n    param_grid = {'discretizer__strategy': ['uniform', 'quantile', 'kmeans'],\n                  'discretizer__n_bins': np.arange(2,11)}\n\n    # Define the KBinsDiscretizer and OneHotEncoder and ComplementNB objects\n    discretizer = KBinsDiscretizer(encode='ordinal')\n    onehot = OneHotEncoder(handle_unknown='ignore', drop='first')\n\n    # Create the pipeline\n    pipeline = Pipeline([('discretizer', discretizer), ('onehot', onehot), ('clf', clf)])\n\n    # Create the cross-validation object using StratifiedKFold to ensure the class distribution is the same across all the folds\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n\n    # Create the GridSearchCV object\n    grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='f1')\n    \n    # Fit the GridSearchCV object to the training data\n    grid_search.fit(X_train, y_train)\n\n    # Print the best parameters and the best score\n    print(\"Best discretization parameters:\", grid_search.best_params_)\n    print(\"Best score:\", grid_search.best_score_)\n    \n    # Return optimal values for n_bins and strategy\n    return grid_search.best_params_['discretizer__n_bins'], grid_search.best_params_['discretizer__strategy']","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.595796Z","iopub.execute_input":"2024-06-26T14:17:02.596112Z","iopub.status.idle":"2024-06-26T14:17:02.612955Z","shell.execute_reply.started":"2024-06-26T14:17:02.596078Z","shell.execute_reply":"2024-06-26T14:17:02.611608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter","metadata":{}},{"cell_type":"code","source":"def tune_clf_hyperparameters(clf, param_grid, X_train, y_train):\n    '''\n    This function optimize the hyperparameters for a classifier by searching over a specified hyperparameter grid. It uses \n    GridSearchCV and cross-validation (StratifiedKFold) to evaluate different combinations of hyperparameters, and selects  \n    the combination with the highest f1-score. The function returns the best classifier with the optimal hyperparameters.\n    '''\n    \n    # Create the cross-validation object using StratifiedKFold to ensure the class distribution is the same across all the folds\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n\n    # Create the GridSearchCV object\n    clf_grid = GridSearchCV(clf, param_grid, cv=cv, scoring=f1_metric, n_jobs=-1)\n\n    # Fit the GridSearchCV object to the training data\n    clf_grid.fit(X_train, y_train)\n\n    # Get the best hyperparameters\n    print(\"Best hyperparameters:\\n\", clf_grid.best_params_)\n    \n    # Return best_estimator_ attribute which gives us the best model that has been fitted to the training data\n    return clf_grid.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.623053Z","iopub.execute_input":"2024-06-26T14:17:02.623489Z","iopub.status.idle":"2024-06-26T14:17:02.630992Z","shell.execute_reply.started":"2024-06-26T14:17:02.623451Z","shell.execute_reply":"2024-06-26T14:17:02.629760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN Model Building","metadata":{}},{"cell_type":"code","source":"# Perform train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.633225Z","iopub.execute_input":"2024-06-26T14:17:02.633691Z","iopub.status.idle":"2024-06-26T14:17:02.653132Z","shell.execute_reply.started":"2024-06-26T14:17:02.633649Z","shell.execute_reply":"2024-06-26T14:17:02.651770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale the training and test data using the same scaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Convert training and test sets from numpy array to pandas dataframes\nX_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\nX_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.654686Z","iopub.execute_input":"2024-06-26T14:17:02.655144Z","iopub.status.idle":"2024-06-26T14:17:02.671530Z","shell.execute_reply.started":"2024-06-26T14:17:02.655099Z","shell.execute_reply":"2024-06-26T14:17:02.670276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define hyperparameters grid to search\nparam_grid = [{'n_neighbors': np.arange(2, 30), 'metric': ['euclidean','manhattan'], 'weights': ['uniform']},\n              {'n_neighbors': np.arange(2, 30), 'metric': ['minkowski'], 'p': [3,4,5], 'weights': ['uniform']}]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.673115Z","iopub.execute_input":"2024-06-26T14:17:02.673474Z","iopub.status.idle":"2024-06-26T14:17:02.679808Z","shell.execute_reply.started":"2024-06-26T14:17:02.673441Z","shell.execute_reply":"2024-06-26T14:17:02.678671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a KNN classifier object\nknn = KNeighborsClassifier()\n\n# Find the best classifier with the optimal hyperparameters\nknn_opt = tune_clf_hyperparameters(knn, param_grid, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:17:02.681381Z","iopub.execute_input":"2024-06-26T14:17:02.682140Z","iopub.status.idle":"2024-06-26T14:18:53.085810Z","shell.execute_reply.started":"2024-06-26T14:17:02.682106Z","shell.execute_reply":"2024-06-26T14:18:53.084465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_column_importance_plot(knn_opt, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:18:53.087558Z","iopub.execute_input":"2024-06-26T14:18:53.087924Z","iopub.status.idle":"2024-06-26T14:19:18.315955Z","shell.execute_reply.started":"2024-06-26T14:18:53.087884Z","shell.execute_reply":"2024-06-26T14:19:18.314567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find Important features with positive feature_importance value\nfeature_importances = drop_column_importance(knn_opt, X_train, y_train, 0)\nselected_features = feature_importances[feature_importances['feature importance']>0]['feature']\n\n# Filter dataset\nX_train = X_train[selected_features]\nX_test = X_test[selected_features]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:19:18.317258Z","iopub.execute_input":"2024-06-26T14:19:18.317611Z","iopub.status.idle":"2024-06-26T14:19:43.273806Z","shell.execute_reply.started":"2024-06-26T14:19:18.317580Z","shell.execute_reply":"2024-06-26T14:19:43.272423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a KNN classifier object\nknn = KNeighborsClassifier()\n\n# Find the best classifier with the optimal hyperparameters\nknn_opt = tune_clf_hyperparameters(knn, param_grid, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:19:43.275865Z","iopub.execute_input":"2024-06-26T14:19:43.276205Z","iopub.status.idle":"2024-06-26T14:20:14.875402Z","shell.execute_reply.started":"2024-06-26T14:19:43.276174Z","shell.execute_reply":"2024-06-26T14:20:14.874051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(knn_opt, X_train, X_test, y_train, y_test, 'KNN')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:20:14.877316Z","iopub.execute_input":"2024-06-26T14:20:14.877741Z","iopub.status.idle":"2024-06-26T14:20:16.623568Z","shell.execute_reply.started":"2024-06-26T14:20:14.877704Z","shell.execute_reply":"2024-06-26T14:20:16.622151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_result = metrics_calculator(knn_opt, X_test, y_test, 'K-Nearest Neighbors')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:20:16.625577Z","iopub.execute_input":"2024-06-26T14:20:16.626063Z","iopub.status.idle":"2024-06-26T14:20:16.805882Z","shell.execute_reply.started":"2024-06-26T14:20:16.626018Z","shell.execute_reply":"2024-06-26T14:20:16.803887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM Model Building","metadata":{}},{"cell_type":"code","source":"# Perform train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:08:42.233068Z","iopub.execute_input":"2024-06-26T17:08:42.233517Z","iopub.status.idle":"2024-06-26T17:08:42.245688Z","shell.execute_reply.started":"2024-06-26T17:08:42.233481Z","shell.execute_reply":"2024-06-26T17:08:42.244105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale the training and test data using the same scaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Convert training and test sets from numpy array to pandas dataframes\nX_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\nX_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:08:52.496034Z","iopub.execute_input":"2024-06-26T17:08:52.496454Z","iopub.status.idle":"2024-06-26T17:08:52.515446Z","shell.execute_reply.started":"2024-06-26T17:08:52.496423Z","shell.execute_reply":"2024-06-26T17:08:52.513093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Weights associated with classes\nclass_weights = [{0:x, 1:1.0-x} for x in np.linspace(0.001,0.5,12)]\n\n# Define the hyperparameter grid to search\nparam_grid = [{'kernel': ['poly'], \n               'degree': [2,3,4,5], \n               'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n               'C': [0.01,0.1,1, 10, 100, 1000],\n               'class_weight': class_weights},\n                  \n              {'kernel': ['rbf','sigmoid'],\n               'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n               'C': [0.01,0.1,1, 10, 100, 1000],\n               'class_weight': class_weights},\n                  \n              {'kernel': ['linear'],\n               'C': [0.01,0.1,1, 10, 100, 1000],\n               'class_weight': class_weights}\n             ]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:09:02.372881Z","iopub.execute_input":"2024-06-26T17:09:02.373409Z","iopub.status.idle":"2024-06-26T17:09:02.382185Z","shell.execute_reply.started":"2024-06-26T17:09:02.373375Z","shell.execute_reply":"2024-06-26T17:09:02.380965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Weights associated with classes\nclass_weights = [{0:x, 1:1.0-x} for x in np.linspace(0.001,0.5,12)]\n\n# Define the hyperparameter grid to search\nparam_grid = [{'kernel': ['rbf'],\n               'gamma': [0.1, 0.01, 0.001, 0.0001], \n               'C': [0.1, 1, 10, 100, 1000],\n               'class_weight': class_weights}]  ","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:09:13.811244Z","iopub.execute_input":"2024-06-26T17:09:13.811675Z","iopub.status.idle":"2024-06-26T17:09:13.819620Z","shell.execute_reply.started":"2024-06-26T17:09:13.811640Z","shell.execute_reply":"2024-06-26T17:09:13.818032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a SVC object\nsvm = SVC(probability=True, random_state=0)\n\n# Find the best classifier with the optimal hyperparameters\nsvm_opt = tune_clf_hyperparameters(svm, param_grid, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:09:25.171034Z","iopub.execute_input":"2024-06-26T17:09:25.171504Z","iopub.status.idle":"2024-06-26T17:18:53.262961Z","shell.execute_reply.started":"2024-06-26T17:09:25.171467Z","shell.execute_reply":"2024-06-26T17:18:53.261238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_column_importance_plot(svm_opt, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:19:07.439510Z","iopub.execute_input":"2024-06-26T17:19:07.439925Z","iopub.status.idle":"2024-06-26T17:19:48.220180Z","shell.execute_reply.started":"2024-06-26T17:19:07.439884Z","shell.execute_reply":"2024-06-26T17:19:48.218832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find Important features with positive feature_importance value\nfeature_importances = drop_column_importance(svm_opt, X_train, y_train, 0)\nselected_features = feature_importances[feature_importances['feature importance']>0.01]['feature']  # Threshold value of 0.01\n\n# Filter dataset\nX_train = X_train[selected_features]\nX_test = X_test[selected_features]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:19:48.222701Z","iopub.execute_input":"2024-06-26T17:19:48.223574Z","iopub.status.idle":"2024-06-26T17:20:28.608426Z","shell.execute_reply.started":"2024-06-26T17:19:48.223526Z","shell.execute_reply":"2024-06-26T17:20:28.606539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a SVC object\nsvm = SVC(probability=True, random_state=0)\n\n# Find the best classifier with the optimal hyperparameters\nsvm_opt = tune_clf_hyperparameters(svm, param_grid, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:20:28.609724Z","iopub.execute_input":"2024-06-26T17:20:28.610091Z","iopub.status.idle":"2024-06-26T17:27:42.323126Z","shell.execute_reply.started":"2024-06-26T17:20:28.610058Z","shell.execute_reply":"2024-06-26T17:27:42.321678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(svm_opt, X_train, X_test, y_train, y_test, 'SVM')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:27:46.834684Z","iopub.execute_input":"2024-06-26T17:27:46.835094Z","iopub.status.idle":"2024-06-26T17:27:47.852842Z","shell.execute_reply.started":"2024-06-26T17:27:46.835059Z","shell.execute_reply":"2024-06-26T17:27:47.851702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the final performance of SVM classifier\nsvm_result = metrics_calculator(svm_opt, X_test, y_test, 'SVM')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:27:54.167495Z","iopub.execute_input":"2024-06-26T17:27:54.167898Z","iopub.status.idle":"2024-06-26T17:27:54.208460Z","shell.execute_reply.started":"2024-06-26T17:27:54.167865Z","shell.execute_reply":"2024-06-26T17:27:54.207058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree Model Building","metadata":{}},{"cell_type":"code","source":"# Weights associated with classes\nclass_weights = [{0:x, 1:1.0-x} for x in np.linspace(0.001,1,20)]\n    \n# Define the hyperparameter grid\nparam_grid = {'criterion': ['gini', 'entropy', 'log_loss'],\n              'max_depth': np.arange(1, 10),\n              'min_samples_split': np.arange(1, 10),\n              'min_samples_leaf': np.arange(1, 10),\n              'max_features': [None, 'sqrt', 'log2'],\n              'class_weight': class_weights} ","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:20:16.807464Z","iopub.execute_input":"2024-06-26T14:20:16.807886Z","iopub.status.idle":"2024-06-26T14:20:16.816564Z","shell.execute_reply.started":"2024-06-26T14:20:16.807852Z","shell.execute_reply":"2024-06-26T14:20:16.815316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n\n# Create a  Decision Tree Classifier object\ndt = DecisionTreeClassifier(random_state=0)\n\n# Find the best classifier with the optimal hyperparameters\ndt_opt = tune_clf_hyperparameters(dt, param_grid, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T14:20:16.819230Z","iopub.execute_input":"2024-06-26T14:20:16.819941Z","iopub.status.idle":"2024-06-26T15:05:33.443180Z","shell.execute_reply.started":"2024-06-26T14:20:16.819899Z","shell.execute_reply":"2024-06-26T15:05:33.441956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_column_importance_plot(dt_opt, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:05:33.444668Z","iopub.execute_input":"2024-06-26T15:05:33.445032Z","iopub.status.idle":"2024-06-26T15:05:35.198037Z","shell.execute_reply.started":"2024-06-26T15:05:33.444999Z","shell.execute_reply":"2024-06-26T15:05:35.196809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find Important features with positive feature_importance value\nfeature_importances = drop_column_importance(dt_opt, X_train, y_train, 0)\nselected_features = feature_importances[feature_importances['feature importance']>0.01]['feature'] # Threshold value of 0.01\n\n# Filter dataset\nX_train = X_train[selected_features]\nX_test = X_test[selected_features]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:05:35.199977Z","iopub.execute_input":"2024-06-26T15:05:35.200430Z","iopub.status.idle":"2024-06-26T15:05:36.520039Z","shell.execute_reply.started":"2024-06-26T15:05:35.200386Z","shell.execute_reply":"2024-06-26T15:05:36.518835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a  Decision Tree Classifier object\ndt = DecisionTreeClassifier(random_state=0)\n\n# Find the best classifier with the optimal hyperparameters\ndt_opt = tune_clf_hyperparameters(dt, param_grid, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:05:36.521695Z","iopub.execute_input":"2024-06-26T15:05:36.522070Z","iopub.status.idle":"2024-06-26T15:42:47.103299Z","shell.execute_reply.started":"2024-06-26T15:05:36.522038Z","shell.execute_reply":"2024-06-26T15:42:47.101588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(dt_opt, X_train, X_test, y_train, y_test, 'Decision Tree')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:42:47.104713Z","iopub.execute_input":"2024-06-26T15:42:47.105153Z","iopub.status.idle":"2024-06-26T15:42:47.920983Z","shell.execute_reply.started":"2024-06-26T15:42:47.105111Z","shell.execute_reply":"2024-06-26T15:42:47.919833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_result = metrics_calculator(dt_opt, X_test, y_test, 'Decision Tree')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:42:47.922241Z","iopub.execute_input":"2024-06-26T15:42:47.922682Z","iopub.status.idle":"2024-06-26T15:42:47.949986Z","shell.execute_reply.started":"2024-06-26T15:42:47.922639Z","shell.execute_reply":"2024-06-26T15:42:47.948783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Model Building","metadata":{}},{"cell_type":"code","source":"# Weights associated with classes\nclass_weights = [{0:x, 1:1.0-x} for x in np.linspace(0.001,1,20)]\n\n# Define the hyperparameter grid to search\nparam_grid = {\n    'n_estimators': [50, 100, 150], \n    'max_depth': np.arange(5, 12),\n    'min_samples_split': [1, 2, 3],\n    'min_samples_leaf': [1, 2, 3],\n    'class_weight': class_weights\n}","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:42:47.951458Z","iopub.execute_input":"2024-06-26T15:42:47.952514Z","iopub.status.idle":"2024-06-26T15:42:47.959763Z","shell.execute_reply.started":"2024-06-26T15:42:47.952465Z","shell.execute_reply":"2024-06-26T15:42:47.958590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n\n# Create a random forest classifier object\nrf = RandomForestClassifier(criterion='gini', max_features=None, bootstrap=True, random_state=0)\n\n# Find the best classifier with the optimal hyperparameters\nrf_opt = tune_clf_hyperparameters(rf, param_grid, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:42:47.961223Z","iopub.execute_input":"2024-06-26T15:42:47.962101Z","iopub.status.idle":"2024-06-26T16:31:06.878808Z","shell.execute_reply.started":"2024-06-26T15:42:47.962054Z","shell.execute_reply":"2024-06-26T16:31:06.877553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_column_importance_plot(rf_opt, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:31:06.880679Z","iopub.execute_input":"2024-06-26T16:31:06.881145Z","iopub.status.idle":"2024-06-26T16:31:33.925637Z","shell.execute_reply.started":"2024-06-26T16:31:06.881102Z","shell.execute_reply":"2024-06-26T16:31:33.924378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(rf_opt, X_train, X_test, y_train, y_test, 'Primary RF')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:31:33.926981Z","iopub.execute_input":"2024-06-26T16:31:33.927306Z","iopub.status.idle":"2024-06-26T16:31:34.896740Z","shell.execute_reply.started":"2024-06-26T16:31:33.927277Z","shell.execute_reply":"2024-06-26T16:31:34.895440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build random forest classifier object considering the obtained optimal values for hyperparameters\nrf_final = RandomForestClassifier(criterion='gini', max_features=None, bootstrap=True,  n_estimators=100, \n                                  max_depth = 9,  min_samples_leaf=6, min_samples_split=2,\n                                  class_weight={0: 0.58, 1: 0.42}, random_state=0)\n                             \n                            \n# Train the final Random Forest model\nrf_final.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:31:34.898808Z","iopub.execute_input":"2024-06-26T16:31:34.899256Z","iopub.status.idle":"2024-06-26T16:31:35.625163Z","shell.execute_reply.started":"2024-06-26T16:31:34.899213Z","shell.execute_reply":"2024-06-26T16:31:35.624109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(rf_final, X_train, X_test, y_train, y_test, 'Random Forest')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:31:35.626575Z","iopub.execute_input":"2024-06-26T16:31:35.626986Z","iopub.status.idle":"2024-06-26T16:31:36.703372Z","shell.execute_reply.started":"2024-06-26T16:31:35.626948Z","shell.execute_reply":"2024-06-26T16:31:36.702176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_result = metrics_calculator(rf_final, X_test, y_test, 'Random Forest')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:31:36.704474Z","iopub.execute_input":"2024-06-26T16:31:36.704819Z","iopub.status.idle":"2024-06-26T16:31:36.757367Z","shell.execute_reply.started":"2024-06-26T16:31:36.704789Z","shell.execute_reply":"2024-06-26T16:31:36.756276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AdaBoost Model Building","metadata":{}},{"cell_type":"code","source":"# Define the hyperparameter grid for AdaBoost\nada_param_grid = {\n    'base_estimator__max_depth': [3, 5, 7],\n    'base_estimator__min_samples_split': [3, 5, 7],\n    'base_estimator__min_samples_leaf': [1, 2, 3],\n    'n_estimators': [50, 100, 150],\n    'learning_rate': [0.8, 0.9, 1]\n}","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:31:36.759126Z","iopub.execute_input":"2024-06-26T16:31:36.759490Z","iopub.status.idle":"2024-06-26T16:31:36.765324Z","shell.execute_reply.started":"2024-06-26T16:31:36.759460Z","shell.execute_reply":"2024-06-26T16:31:36.764157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:38:55.305776Z","iopub.execute_input":"2024-06-26T16:38:55.306179Z","iopub.status.idle":"2024-06-26T16:38:55.312225Z","shell.execute_reply.started":"2024-06-26T16:38:55.306143Z","shell.execute_reply":"2024-06-26T16:38:55.310736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n\n# Create the Decision Tree classifier as the base estimator\ndt = DecisionTreeClassifier(criterion='gini', max_features=None, random_state=0)\n\n# Create the AdaBoost classifier using Decision Tree as base estimator\nada = AdaBoostClassifier(base_estimator=dt, random_state=0)\n\n# Find the best AdaBoost classifier with the optimal hyperparameters\nada_opt = tune_clf_hyperparameters(ada, ada_param_grid, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:39:29.598063Z","iopub.execute_input":"2024-06-26T16:39:29.598491Z","iopub.status.idle":"2024-06-26T16:47:59.898788Z","shell.execute_reply.started":"2024-06-26T16:39:29.598449Z","shell.execute_reply":"2024-06-26T16:47:59.897061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_column_importance_plot(ada_opt, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:48:12.699086Z","iopub.execute_input":"2024-06-26T16:48:12.700005Z","iopub.status.idle":"2024-06-26T16:49:53.087562Z","shell.execute_reply.started":"2024-06-26T16:48:12.699954Z","shell.execute_reply":"2024-06-26T16:49:53.086304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(ada_opt, X_train, X_test, y_train, y_test, 'Primary AdaBoost')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:50:01.313572Z","iopub.execute_input":"2024-06-26T16:50:01.313952Z","iopub.status.idle":"2024-06-26T16:50:02.489155Z","shell.execute_reply.started":"2024-06-26T16:50:01.313921Z","shell.execute_reply":"2024-06-26T16:50:02.485264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt = DecisionTreeClassifier(criterion='gini', max_features=None, random_state=0, max_depth=5, min_samples_leaf=2, min_samples_split=5)\n\n# Create the AdaBoost classifier using Decision Tree as base estimator\nada_final = AdaBoostClassifier(base_estimator=dt, random_state=0, learning_rate=0.8, n_estimators=100)\n\n# Train the final AdaBoost classifier\nada_final.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:50:06.180557Z","iopub.execute_input":"2024-06-26T16:50:06.180945Z","iopub.status.idle":"2024-06-26T16:50:07.622951Z","shell.execute_reply.started":"2024-06-26T16:50:06.180913Z","shell.execute_reply":"2024-06-26T16:50:07.621837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(ada_final, X_train, X_test, y_train, y_test, 'AdaBoost')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:50:10.571089Z","iopub.execute_input":"2024-06-26T16:50:10.571925Z","iopub.status.idle":"2024-06-26T16:50:11.719605Z","shell.execute_reply.started":"2024-06-26T16:50:10.571884Z","shell.execute_reply":"2024-06-26T16:50:11.718440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ada_result = metrics_calculator(ada_final, X_test, y_test, 'AdaBoost')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:50:14.905487Z","iopub.execute_input":"2024-06-26T16:50:14.905865Z","iopub.status.idle":"2024-06-26T16:50:14.986694Z","shell.execute_reply.started":"2024-06-26T16:50:14.905835Z","shell.execute_reply":"2024-06-26T16:50:14.985568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradient Boosting Model Building","metadata":{}},{"cell_type":"code","source":"# Define the hyperparameter grid for tuning\ngbc_param_grid = {\n    'n_estimators': [50, 100, 200, 300, 400, 500],\n    'max_depth': [1, 2, 3, 4, 5],\n    'min_samples_split': [2, 4, 6, 8, 10],\n    'min_samples_leaf': [1, 2, 3, 4, 5],\n    'max_features': [None, 'sqrt', 'log2'],\n    'loss': ['deviance', 'exponential'],\n    'criterion': ['friedman_mse', 'squared_error'],\n    'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]\n}","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:50:17.225903Z","iopub.execute_input":"2024-06-26T16:50:17.226871Z","iopub.status.idle":"2024-06-26T16:50:17.233801Z","shell.execute_reply.started":"2024-06-26T16:50:17.226827Z","shell.execute_reply":"2024-06-26T16:50:17.232549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the hyperparameter grid for tuning\ngbc_param_grid = {\n    'n_estimators': [50, 100, 150],\n    'max_depth': [4, 5, 6],\n    'min_samples_split': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'subsample': [0.9, 1.0],\n    'learning_rate': [0.3, 0.4, 0.5]\n}","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:50:20.712209Z","iopub.execute_input":"2024-06-26T16:50:20.712625Z","iopub.status.idle":"2024-06-26T16:50:20.718290Z","shell.execute_reply.started":"2024-06-26T16:50:20.712592Z","shell.execute_reply":"2024-06-26T16:50:20.717246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n\n# Initialize the Gradient Boosting Classifier\ngbc = GradientBoostingClassifier(max_features=None, loss='deviance', criterion='friedman_mse', random_state=0)\n\n# Find the best hyperparameters from the tuning process\ngbc_opt = tune_clf_hyperparameters(gbc, gbc_param_grid, X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T16:50:23.344685Z","iopub.execute_input":"2024-06-26T16:50:23.345115Z","iopub.status.idle":"2024-06-26T16:59:05.127427Z","shell.execute_reply.started":"2024-06-26T16:50:23.345081Z","shell.execute_reply":"2024-06-26T16:59:05.126078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_column_importance_plot(gbc_opt, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:02:19.857818Z","iopub.execute_input":"2024-06-26T17:02:19.858257Z","iopub.status.idle":"2024-06-26T17:02:51.103539Z","shell.execute_reply.started":"2024-06-26T17:02:19.858221Z","shell.execute_reply":"2024-06-26T17:02:51.102203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(gbc_opt, X_train, X_test, y_train, y_test, 'Primary Grad. Boosting')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:02:55.532006Z","iopub.execute_input":"2024-06-26T17:02:55.532444Z","iopub.status.idle":"2024-06-26T17:02:56.482273Z","shell.execute_reply.started":"2024-06-26T17:02:55.532408Z","shell.execute_reply":"2024-06-26T17:02:56.481055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the Gradient Boosting Classifier\ngbc_final = GradientBoostingClassifier(max_features=None, loss='deviance', criterion='friedman_mse',\n                                 learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0,\n                                 min_samples_leaf=4, min_samples_split=2, random_state=0)\n\n# Train the final AdaBoost classifier\ngbc_final.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:03:02.270683Z","iopub.execute_input":"2024-06-26T17:03:02.271085Z","iopub.status.idle":"2024-06-26T17:03:03.417826Z","shell.execute_reply.started":"2024-06-26T17:03:02.271052Z","shell.execute_reply":"2024-06-26T17:03:03.416403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(gbc_final, X_train, X_test, y_train, y_test, 'Gradient Boosting')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:03:07.116880Z","iopub.execute_input":"2024-06-26T17:03:07.117272Z","iopub.status.idle":"2024-06-26T17:03:07.899586Z","shell.execute_reply.started":"2024-06-26T17:03:07.117239Z","shell.execute_reply":"2024-06-26T17:03:07.898422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbc_result = metrics_calculator(gbc_final, X_test, y_test, 'Gradient Boosting')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:03:11.137777Z","iopub.execute_input":"2024-06-26T17:03:11.138898Z","iopub.status.idle":"2024-06-26T17:03:11.165610Z","shell.execute_reply.started":"2024-06-26T17:03:11.138855Z","shell.execute_reply":"2024-06-26T17:03:11.164502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost Model Building","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:03:15.331918Z","iopub.execute_input":"2024-06-26T17:03:15.332321Z","iopub.status.idle":"2024-06-26T17:03:15.344368Z","shell.execute_reply.started":"2024-06-26T17:03:15.332288Z","shell.execute_reply":"2024-06-26T17:03:15.342415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define imbalance ratio\nratio = sum(y_train==0)/sum(y_train==1) \n\n# Define the hyperparameter grid to search\nxgb_param_grid = {\n    'max_depth': [5, 6, 7],\n    'learning_rate': [0.1, 0.2, 0.3],\n    'n_estimators': [50, 100, 200],\n    'min_child_weight': [1, 5, 10],\n    'scale_pos_weight': [ratio, ratio*1.3, ratio*1.5],\n    'subsample': [0.6, 0.8, 1.0],\n    'colsample_bytree': [0.6, 0.8, 1.0],\n    'colsample_bylevel': [0.6, 0.8, 1.0],\n    'reg_alpha': [0, 0.1, 1],\n    'reg_lambda': [0, 0.1, 1],\n    'max_delta_step': [0, 1, 2],\n    'gamma': [0, 0.1, 1],\n    'max_leaf_nodes': [2, 4, 6]\n}","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:03:18.591818Z","iopub.execute_input":"2024-06-26T17:03:18.592891Z","iopub.status.idle":"2024-06-26T17:03:18.601487Z","shell.execute_reply.started":"2024-06-26T17:03:18.592847Z","shell.execute_reply":"2024-06-26T17:03:18.600224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the XGBoost Classifier\nxgb_opt = XGBClassifier(max_depth=5,\n                        learning_rate=0.3,\n                        n_estimators=200,\n                        min_child_weight=1,\n                        scale_pos_weight=1.5,\n                        colsample_bytree=0.8,\n                        gamma=0.1,\n                        booster='gbtree',\n                        objective='binary:logistic',\n                        eval_metric='error', \n                        random_state=0)\n\n# Train the XGBoost Classifier\nxgb_opt.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:03:22.221367Z","iopub.execute_input":"2024-06-26T17:03:22.222310Z","iopub.status.idle":"2024-06-26T17:03:22.385286Z","shell.execute_reply.started":"2024-06-26T17:03:22.222271Z","shell.execute_reply":"2024-06-26T17:03:22.384051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_column_importance_plot(xgb_opt, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:03:26.251999Z","iopub.execute_input":"2024-06-26T17:03:26.252421Z","iopub.status.idle":"2024-06-26T17:03:36.017939Z","shell.execute_reply.started":"2024-06-26T17:03:26.252384Z","shell.execute_reply":"2024-06-26T17:03:36.016680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find Important features\nfeature_importances = drop_column_importance(xgb_opt, X_train, y_train, 0)\nselected_features = feature_importances[feature_importances['feature importance']>0.002]['feature'] # Threshold value of 0.002\n\n# Filter dataset\nX_train = X_train[selected_features]\nX_test = X_test[selected_features]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:03:41.369956Z","iopub.execute_input":"2024-06-26T17:03:41.370392Z","iopub.status.idle":"2024-06-26T17:03:52.013957Z","shell.execute_reply.started":"2024-06-26T17:03:41.370337Z","shell.execute_reply":"2024-06-26T17:03:52.012883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the XGBoost Classifier\nxgb = XGBClassifier(max_depth=5,\n                    learning_rate=0.3,\n                    n_estimators=200,\n                    min_child_weight=1,\n                    scale_pos_weight=1.5,\n                    colsample_bytree=0.8,\n                    gamma=0.1,\n                    booster='gbtree',\n                    objective='binary:logistic',\n                    eval_metric='error', \n                    random_state=0)\n\n# Train the XGBoost Classifier\nxgb.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:03:59.050043Z","iopub.execute_input":"2024-06-26T17:03:59.050469Z","iopub.status.idle":"2024-06-26T17:03:59.161197Z","shell.execute_reply.started":"2024-06-26T17:03:59.050434Z","shell.execute_reply":"2024-06-26T17:03:59.159889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(xgb, X_train, X_test, y_train, y_test, 'Primary XGBoost')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:04:02.547844Z","iopub.execute_input":"2024-06-26T17:04:02.548255Z","iopub.status.idle":"2024-06-26T17:04:03.565956Z","shell.execute_reply.started":"2024-06-26T17:04:02.548221Z","shell.execute_reply":"2024-06-26T17:04:03.564830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the XGBoost Classifier\nxgb_final = XGBClassifier(max_depth=4,\n                          learning_rate=0.3,\n                          n_estimators=200,\n                          min_child_weight=1,\n                          scale_pos_weight=1.5,\n                          colsample_bytree=0.8,\n                          gamma=0.1,\n                          booster='gbtree',\n                          objective='binary:logistic',\n                          eval_metric='error', \n                          random_state=0)\n\n# Train the XGBoost Classifier\nxgb_final.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:04:05.937473Z","iopub.execute_input":"2024-06-26T17:04:05.937923Z","iopub.status.idle":"2024-06-26T17:04:06.052050Z","shell.execute_reply.started":"2024-06-26T17:04:05.937887Z","shell.execute_reply":"2024-06-26T17:04:06.050501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(xgb_final, X_train, X_test, y_train, y_test, 'XGBoost')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:04:10.049073Z","iopub.execute_input":"2024-06-26T17:04:10.049520Z","iopub.status.idle":"2024-06-26T17:04:11.052548Z","shell.execute_reply.started":"2024-06-26T17:04:10.049484Z","shell.execute_reply":"2024-06-26T17:04:11.050908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_result = metrics_calculator(xgb_final, X_test, y_test, 'XGBoost')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:04:14.368965Z","iopub.execute_input":"2024-06-26T17:04:14.369391Z","iopub.status.idle":"2024-06-26T17:04:14.402531Z","shell.execute_reply.started":"2024-06-26T17:04:14.369330Z","shell.execute_reply":"2024-06-26T17:04:14.401404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"code","source":"# Concatenate previous classifiers perfermance results into a single dataframe\nresults = pd.concat([knn_result,svm_result,\n                     dt_result, rf_result,ada_result, gbc_result, xgb_result], axis=1).T\n\n# Sort the dataframe in descending order based on F1-score values\nresults.sort_values(by='F1-score', ascending=False, inplace=True)\n\n# Color the F1-score column\nresults.style.applymap(lambda x: 'background-color: royalblue', subset='F1-score')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T17:28:14.904668Z","iopub.execute_input":"2024-06-26T17:28:14.905092Z","iopub.status.idle":"2024-06-26T17:28:14.922653Z","shell.execute_reply.started":"2024-06-26T17:28:14.905056Z","shell.execute_reply":"2024-06-26T17:28:14.921413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}